{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de9329eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88ba27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path().resolve().parent\n",
    "DATASET_DIR = BASE_DIR / \"datasets\"\n",
    "EXPORT_DIR = DATASET_DIR / \"exports\"\n",
    "EXPORT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "DATASET_CSV_PATH = EXPORT_DIR / \"spam-dataset.csv\"\n",
    "TRAINING_DATA_PATH = EXPORT_DIR / \"spam-metadata.pkl\"\n",
    "TOKENIZER_DATA_PATH = EXPORT_DIR / \"spam-tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ade10019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text    source\n",
       "0   ham  Go until jurong point, crazy.. Available only ...  sms-spam\n",
       "1   ham                      Ok lar... Joking wif u oni...  sms-spam\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  sms-spam\n",
       "3   ham  U dun say so early hor... U c already then say...  sms-spam\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...  sms-spam"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a95f024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train': array([[  0,   0,   0, ..., 112,  33,  77],\n",
       "        [  0,   0,   0, ...,   3,  12,  18],\n",
       "        [  0,   0,   0, ...,   0,  12,  46],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   1],\n",
       "        [  0,   0,   0, ...,  30, 182,   9],\n",
       "        [  0,   0,   0, ...,   0,   3, 156]]),\n",
       " 'X_test': array([[  0,   0,   0, ...,  11,  70,  19],\n",
       "        [  0,   0,   0, ...,   7, 165,  25],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 186,  56,   5],\n",
       "        [  0,   0,   0, ...,  16,  73,  19],\n",
       "        [  0,   0,   0, ...,  26, 104, 106]]),\n",
       " 'y_train': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32),\n",
       " 'y_test': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'max_num_words': 200,\n",
       " 'max_seq_length': 300,\n",
       " 'label_legend': {'ham': 0, 'spam': 1},\n",
       " 'label_legend_inverted': {'0': 'ham', '1': 'spam'},\n",
       " 'tokenizer': <keras_preprocessing.text.Tokenizer at 0x24eb83d2dc0>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "with open(TRAINING_DATA_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ddf040",
   "metadata": {},
   "source": [
    "#### TRANSFORM EXTRACTED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25bdd1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "max_num_words = data['max_num_words']\n",
    "max_seq_length = data['max_seq_length']\n",
    "label_legend = data['label_legend']\n",
    "label_legend_inverted = data['label_legend_inverted']\n",
    "tokenizer = data['tokenizer']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb60e03",
   "metadata": {},
   "source": [
    "#### CREATE LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb31be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Embedding, SpatialDropout1D, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8494cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 128)          25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 280,794\n",
      "Trainable params: 280,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words, embed_dim, input_length = X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])  \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ac3621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "158/158 [==============================] - 182s 1s/step - loss: 0.2983 - accuracy: 0.8810 - val_loss: 0.1493 - val_accuracy: 0.9505\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 180s 1s/step - loss: 0.1597 - accuracy: 0.9455 - val_loss: 0.1400 - val_accuracy: 0.9569\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 183s 1s/step - loss: 0.1503 - accuracy: 0.9512 - val_loss: 0.1398 - val_accuracy: 0.9557\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 190s 1s/step - loss: 0.1416 - accuracy: 0.9554 - val_loss: 0.1361 - val_accuracy: 0.9557\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 182s 1s/step - loss: 0.1419 - accuracy: 0.9554 - val_loss: 0.1316 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f37d08f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, verbose=1, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f06d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_EXPORT_PATH = EXPORT_DIR / \"spam-model.h5\"\n",
    "model.save(MODEL_EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37adb70b",
   "metadata": {},
   "source": [
    "### Predict New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adb8c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def predict(text_str, max_words = 280, max_sequence = 280, tokenizer=None):\n",
    "    if not tokenizer:\n",
    "        return None\n",
    "    sequences = tokenizer.texts_to_sequences([text_str])\n",
    "    x_input = pad_sequences(sequences, maxlen=max_sequence)\n",
    "    y_output = model.predict(x_input)\n",
    "    top_y_index = np.argmax(y_output)\n",
    "    preds = y_output[top_y_index]\n",
    "    labeled_preds = [{f\"{label_legend_inverted[str(i)]}\": x} for i, x in enumerate(preds)]\n",
    "    return labeled_preds\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60d24ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ham': 0.9494517}, {'spam': 0.050548326}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Hello world\", max_words=max_num_words, max_sequence=max_seq_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d102346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
